---
title: "dataset"
author: "Emanuele Iaccarino"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

```

#HDI analysys
```{r}
library(readr)
library(dplyr)
library(tidyr)
#leggo dataset da locale
HDI_dataset <- read_csv("C:/Users/39388/Downloads/human-development-indexx.csv",
                        col_types = cols(Year = col_double(),
                                         `Human Development Index` = col_double(),
                                         Entity = col_character(),
                                         Code = col_character()))
names(HDI_dataset)[4] <- "Human_Development_Index"
#sistemo il dataset per l'analisi
HDI_dataset <- HDI_dataset %>%
  filter(Year >= 2000) %>%
  group_by(Entity, Year) %>%
  summarize(Human_Development_Index = mean(`Human_Development_Index`, na.rm = TRUE)) %>%
  pivot_wider(names_from = Year, values_from = Human_Development_Index)

head(HDI_dataset)
```
##Cluster
```{r}
require(cluster)
require(factoextra)
HDI_cluster <- HDI_dataset %>% 
  select(`2000`:`2021`)
HDI_cluster=na.omit(HDI_cluster)
HDI_dataset=na.omit(HDI_dataset)
set.seed(123)
HDI_cluster <- HDI_cluster[,2:23]
k <- 5 # Numero di cluster da esplorare
sil <- silhouette(kmeans(HDI_cluster, k)$cluster, dist(HDI_cluster))
plot(sil)

# Esegui l'analisi cluster con il metodo di clustering gerarchico
HDI_cluster_dist <- dist(HDI_cluster, method = "euclidean")
HDI_cluster_hclust <- hclust(HDI_cluster_dist, method = "ward.D2")
HDI_cluster_groups <- cutree(HDI_cluster_hclust, k = k)

HDI_cluster_final <- cbind(HDI_dataset, Group = HDI_cluster_groups)

```

```{r}
# Visualizza il dendrogramma
fviz_dend(HDI_cluster_hclust, k = k)

# Visualizza i cluster in uno spazio bidimensionale
HDI_pca <- prcomp(HDI_cluster)
fviz_cluster(list(data = HDI_pca$x[,1:2], cluster = HDI_cluster_groups), 
             geom = "point", 
             palette = "jco",
             ggtheme = theme_classic()) + 
  ggtitle("Clustering gerarchico (Ward.D2) dei paesi") + 
  theme(plot.title = element_text(hjust = 0.5))
```
```{r}
#aggiungo le info ottenute dal cluster al dataset
HDI_means <- rowMeans(HDI_dataset[, 2:(ncol(HDI_dataset)-1)], na.rm = TRUE)
HDI_dataset_with_means <- cbind(HDI_cluster_final, HDI_means)
names(HDI_dataset_with_means)[ncol(HDI_dataset_with_means)] <- "media"
HDI_group_means <- HDI_dataset_with_means %>%
  group_by(Group) %>%
  summarize(mean_media = mean(media, na.rm = TRUE))
HDI_group_rank <- HDI_group_means %>%
  mutate(rank = min_rank(mean_media)) %>%
  arrange(mean_media)
HDI_clusters_df_labed <- HDI_cluster_final %>% 
  mutate_all(~ case_when(. == 1 ~ "PLS", #paesi lento sviluppo
                         . == 2 ~ "PMR", #paesi medio reddito
                         . == 3 ~ "PVS", #paesi in via di sviluppo
                         . == 4 ~ "PSA", #paesi sviluppo avanzato
                         . == 5 ~ "PE", #paesi emergenti
                         TRUE ~ as.character(.)))
```

```{r}

# Utilizza la funzione unique() per ottenere l'elenco dei gruppi presenti nel dataset
elenco_gruppi <- unique(HDI_clusters_df_labed$Group)
HDI_clusters_df_labed[, -c(1, 24)] <- sapply(HDI_clusters_df_labed[, -c(1, 24)], as.numeric)
HDI_clusters_df_labed$MediaRiga <- rowMeans(HDI_clusters_df_labed[, -c(1, 24)])
#stampo l'elenco dei paesi per ogni gruppo, calcolo la media del valore HDI per paese e per gruppo
for (gruppo in elenco_gruppi) {
  paesi <- HDI_clusters_df_labed$Entity[HDI_clusters_df_labed$Group == gruppo]
  cat("Gruppo:", gruppo, "\n")
  cat("Paesi:", paste(paesi, collapse = ", "), "\n\n")
  
  for (paese in paesi) {
    media_valori <- mean(HDI_clusters_df_labed$MediaRiga[HDI_clusters_df_labed$Group == gruppo & HDI_clusters_df_labed$Entity == paese])
    cat("Paese:", paese, "- Media della riga:", media_valori, "\n")
  }
  
  media_valori_gruppo <- mean(HDI_clusters_df_labed$MediaRiga[HDI_clusters_df_labed$Group == gruppo])
  cat("Media dei valori per gruppo:", media_valori_gruppo, "\n\n")
}
```

##grafico generale
andamento di ogni paese anno per anno divisi in gruppi
```{r}

# Trasforma il dataframe in formato "long"
HDI_cluster_final_long <- gather(HDI_cluster_final, key = "anno", value = "valore", -c("Entity", "Group"))

HDI_cluster_final_long$anno <- as.numeric(HDI_cluster_final_long$anno)

# Crea il grafico utilizzando la colonna "anno" come asse x
ggplot(HDI_cluster_final_long, aes(x = anno, y = valore, color = factor(Group), label = Entity)) +
  geom_point() +
  geom_text(nudge_x = 0.02, nudge_y = 0.02) +
  labs(title = "Analisi Cluster dell'HDI per Paese",
       x = "Anno",
       y = "Valore dell'HDI",
       color = "Gruppo") +
  scale_color_discrete(name = "Gruppo", labels = c("Gruppo 1", "Gruppo 2", "Gruppo 3", "Gruppo 4", "Gruppo 5")) +
  theme_bw()
```
###grafico annuale

```{r}
library(ggplot2)
library(dplyr)

# Filtra le righe per l'anno 2001
HDI_cluster_final_2006 <- HDI_cluster_final_long %>% 
  filter(anno == 2001)

# Crea il grafico utilizzando la colonna "Entity" come etichetta sull'asse x
ggplot(HDI_cluster_final_2006, aes(x = Entity, y = valore, color = factor(Group))) +
  geom_point() +
  labs(title = "Analisi Cluster dell'HDI per Paese (anno 2001)",
       x = "Paese",
       y = "Valore dell'HDI",
       color = "Gruppo") +
  scale_color_discrete(name = "Gruppo", labels = c("Gruppo 1", "Gruppo 2", "Gruppo 3", "Gruppo 4", "Gruppo 5")) +
  coord_flip() +
  theme_bw()
```
##Cluster per ogni annata
```{r}
library(cluster)
library(factoextra)
library(dplyr)

# Inizializza una lista per memorizzare i risultati del clustering per ogni anno
HDI_clusters_list <- list()

# Itera sui diversi anni
for (i in 2:ncol(HDI_dataset)) {
  # Seleziona solo l'anno corrente dal dataset HDI_dataset
  HDI_cluster <- HDI_dataset %>% 
    select(all_of(c("Entity", colnames(HDI_dataset)[i]))) %>%
    na.omit()

  # Applica il clustering K-means
  set.seed(123)
  k <- 5 # Numero di cluster da esplorare
  sil <- silhouette(kmeans(HDI_cluster[, colnames(HDI_dataset)[i]], k)$cluster, dist(HDI_cluster[, colnames(HDI_dataset)[i]]))

  # Esegui l'analisi cluster con il metodo di clustering gerarchico
  HDI_cluster_dist <- dist(HDI_cluster[, colnames(HDI_dataset)[i]], method = "euclidean")
  HDI_cluster_hclust <- hclust(HDI_cluster_dist, method = "ward.D2")
  # Suddividi i paesi in 5 gruppi
  HDI_cluster_groups <- cutree(HDI_cluster_hclust, k = k)
  
  HDI_cluster_final <- cbind(HDI_cluster, Group = HDI_cluster_groups)
  
  # Visualizza il dendrogramma
  fviz_dend(HDI_cluster_hclust, k = k)
  
  # Aggiungi la media dell'HDI per ogni paese e il ranking dei gruppi
  HDI_means <- HDI_cluster_final[, colnames(HDI_dataset)[i]]
  HDI_dataset_with_means <- cbind(HDI_cluster_final[,c(1,3)], HDI_means)
  HDI_group_means <- HDI_dataset_with_means %>%
    group_by(Group) %>%
    summarize(mean_media = mean(col(HDI_dataset)[i], na.rm = TRUE))
  HDI_group_rank <- HDI_group_means %>%
    mutate(rank = min_rank(mean_media)) %>%
    arrange(mean_media)
  HDI_clusters_df_labed <- HDI_cluster_final 
  
  HDI_clusters_df_labed <- HDI_clusters_df_labed %>% 
    rename(New_Col_Name = colnames(HDI_clusters_df_labed)[2])
  
  HDI_clusters_list <- append(HDI_clusters_list, list(HDI_clusters_df_labed))
}

HDI_clusters_list


```
per ogni annata creo un cluster, assegnano ad ogni cluster formato la categoria corrispondente in base al valore di HDI
```{r}

HDI_clusters_list[[1]] %>% 
  mutate_all(~ case_when(. == 1 ~ "PLS", #paesi lento sviluppo(R1)
                         . == 2 ~ "PVS", #paesi in via di sviluppo (R4)
                         . == 3 ~ "PMR", #paesi medio reddito (R3)
                         . == 4 ~ "PSA", #paesi sviluppo avanzato(R5)
                         . == 5 ~ "PE", #paesi emergenti(R2)
                         TRUE ~ as.character(.)))
HDI_clusters_list[[2]] %>% 
  mutate_all(~ case_when(. == 1 ~ "PLS", #paesi lento sviluppo (R1)
                         . == 2 ~ "PVS", #paesi in via di sviluppo (R4)
                         . == 3 ~ "PSA", #paesi sviluppo avanzato (R5)
                         . == 4 ~ "PE", #paesi emergenti (R2)
                         . == 5 ~ "PMR", #paesi medio reddito (R3)
                         TRUE ~ as.character(.)))
HDI_clusters_list[[3]] %>% 
  mutate_all(~ case_when(. == 1 ~ "PLS", #paesi lento sviluppo (R1)
                         . == 2 ~ "PVS", #paesi in via di sviluppo (R4)
                         . == 3 ~ "PSA", #paesi sviluppo avanzato (R5)
                         . == 4 ~ "PMR", #paesi medio reddito (R3)
                         . == 5 ~ "PE", #paesi emergenti (R2)
                         TRUE ~ as.character(.)))
HDI_clusters_list[[4]] %>% 
  mutate_all(~ case_when(. == 1 ~ "PLS", #paesi lento sviluppo (R1)
                         . == 2 ~ "PVS", #paesi in via di sviluppo (R4)
                         . == 3 ~ "PSA", #paesi sviluppo avanzato (R5)
                         . == 4 ~ "PE", #paesi emergenti (R2)
                         . == 5 ~ "PMR", #paesi medio reddito (R3)
                         TRUE ~ as.character(.)))
HDI_clusters_list[[5]] %>% 
  mutate_all(~ case_when(. == 1 ~ "PLS", #paesi lento sviluppo (R1)
                         . == 2 ~ "PVS", #paesi in via di sviluppo (R4)
                         . == 3 ~ "PSA", #paesi sviluppo avanzato (R5)
                         . == 4 ~ "PE", #paesi emergenti (R2)
                         . == 5 ~ "PMR", #paesi medio reddito (R3)
                         TRUE ~ as.character(.)))
HDI_clusters_list[[6]] %>% 
  mutate_all(~ case_when(. == 1 ~ "PLS", #paesi lento sviluppo (R1)
                         . == 2 ~ "PVS", #paesi in via di sviluppo (R4)
                         . == 3 ~ "PSA", #paesi sviluppo avanzato (R5)
                         . == 4 ~ "PE", #paesi emergenti (R2)
                         . == 5 ~ "PMR", #paesi medio reddito (R3)
                         TRUE ~ as.character(.)))
HDI_clusters_list[[7]] %>% 
  mutate_all(~ case_when(. == 1 ~ "PE", #paesi emergenti (R2)
                         . == 2 ~ "PVS", #paesi in via di sviluppo (R4)
                         . == 3 ~ "PSA", #paesi sviluppo avanzato (R5)
                         . == 4 ~ "PMR", #paesi medio reddito (R3)
                         . == 5 ~ "PLS", #paesi lento sviluppo (R1)
                         TRUE ~ as.character(.)))
HDI_clusters_list[[8]] %>% 
  mutate_all(~ case_when(. == 1 ~ "PLS", #paesi lento sviluppo (R1)
                         . == 2 ~ "PVS", #paesi in via di sviluppo (R4)
                         . == 3 ~ "PSA", #paesi sviluppo avanzato (R5)
                         . == 4 ~ "PE", #paesi emergenti (R2)
                         . == 5 ~ "PMR", #paesi medio reddito (R3)
                         TRUE ~ as.character(.)))
HDI_clusters_list[[9]] %>% 
  mutate_all(~ case_when(. == 1 ~ "PLS", #paesi lento sviluppo (R1)
                         . == 2 ~ "PMR", #paesi medio reddito (R3)
                         . == 3 ~ "PSA", #paesi sviluppo avanzato (R5)
                         . == 4 ~ "PVS", #paesi in via di sviluppo (R4)
                         . == 5 ~ "PE", #paesi emergenti (R2)
                         TRUE ~ as.character(.)))
HDI_clusters_list[[10]] %>% 
  mutate_all(~ case_when(. == 1 ~ "PLS", #paesi lento sviluppo (R1)
                         . == 2 ~ "PMR", #paesi medio reddito (R3)
                         . == 3 ~ "PSA", #paesi sviluppo avanzato (R5)
                         . == 4 ~ "PVS", #paesi in via di sviluppo (R4)
                         . == 5 ~ "PE", #paesi emergenti (R2)
                         TRUE ~ as.character(.)))
HDI_clusters_list[[11]] %>% 
  mutate_all(~ case_when(. == 1 ~ "PLS", #paesi lento sviluppo (R1)
                         . == 2 ~ "PMR", #paesi medio reddito (R3)
                         . == 3 ~ "PVS", #paesi in via di sviluppo (R4)
                         . == 4 ~ "PSA", #paesi sviluppo avanzato (R5)
                         . == 5 ~ "PE", #paesi emergenti (R2)
                         TRUE ~ as.character(.)))
HDI_clusters_list[[12]] %>% 
  mutate_all(~ case_when(. == 1 ~ "PE", #paesi emergenti (R2)
                         . == 2 ~ "PVS", #paesi in via di sviluppo (R4)
                         . == 3 ~ "PSA", #paesi sviluppo avanzato (R5)
                         . == 4 ~ "PMR", #paesi medio reddito (R3)
                         . == 5 ~ "PLS", #paesi lento sviluppo (R1)
                         TRUE ~ as.character(.)))
HDI_clusters_list[[13]] %>% 
  mutate_all(~ case_when(. == 1 ~ "PE", #paesi emergenti (R2)
                         . == 2 ~ "PVS", #paesi in via di sviluppo (R4)
                         . == 3 ~ "PMR", #paesi medio reddito (R3)
                         . == 4 ~ "PSA", #paesi sviluppo avanzato (R5)
                         . == 5 ~ "PLS", #paesi lento sviluppo (R1)
                         TRUE ~ as.character(.)))
HDI_clusters_list[[14]] %>% 
  mutate_all(~ case_when(. == 1 ~ "PLS", #paesi lento sviluppo (R1)
                         . == 2 ~ "PMR", #paesi medio reddito (R3)
                         . == 3 ~ "PVS", #paesi in via di sviluppo (R4)
                         . == 4 ~ "PE", #paesi emergenti (R2)
                         . == 5 ~ "PSA", #paesi sviluppo avanzato (R5)
                         TRUE ~ as.character(.)))
HDI_clusters_list[[15]] %>% 
  mutate_all(~ case_when(. == 1 ~ "PLS", #paesi lento sviluppo (R1)
                         . == 2 ~ "PVS", #paesi in via di sviluppo (R4)
                         . == 3 ~ "PMR", #paesi medio reddito (R3)
                         . == 4 ~ "PSA", #paesi sviluppo avanzato (R5)
                         . == 5 ~ "PE", #paesi emergenti (R2)
                         TRUE ~ as.character(.)))
HDI_clusters_list[[16]] %>% 
  mutate_all(~ case_when(. == 1 ~ "PLS", #paesi lento sviluppo (R1)
                         . == 2 ~ "PVS", #paesi in via di sviluppo (R4)
                         . == 3 ~ "PSA", #paesi sviluppo avanzato (R5)
                         . == 4 ~ "PE", #paesi emergenti (R2)
                         . == 5 ~ "PMR", #paesi medio reddito (R3)
                         TRUE ~ as.character(.)))
HDI_clusters_list[[17]] %>% 
  mutate_all(~ case_when(. == 1 ~ "PLS", #paesi lento sviluppo (R1)
                         . == 2 ~ "PVS", #paesi in via di sviluppo (R4)
                         . == 3 ~ "PMR", #paesi medio reddito (R3)
                         . == 4 ~ "PSA", #paesi sviluppo avanzato (R5)
                         . == 5 ~ "PE", #paesi emergenti (R2)
                         TRUE ~ as.character(.)))
HDI_clusters_list[[18]] %>% 
  mutate_all(~ case_when(. == 1 ~ "PLS", #paesi lento sviluppo (R1)
                         . == 2 ~ "PVS", #paesi in via di sviluppo (R4)
                         . == 3 ~ "PMR", #paesi medio reddito (R3)
                         . == 4 ~ "PE", #paesi emergenti (R2)
                         . == 5 ~ "PSA", #paesi sviluppo avanzato (R5)
                         TRUE ~ as.character(.)))
HDI_clusters_list[[19]] %>% 
  mutate_all(~ case_when(. == 1 ~ "PLS", #paesi lento sviluppo (R1)
                         . == 2 ~ "PVS", #paesi in via di sviluppo (R4)
                         . == 3 ~ "PMR", #paesi medio reddito (R3)
                         . == 4 ~ "PE", #paesi emergenti (R2)
                         . == 5 ~ "PSA", #paesi sviluppo avanzato (R5)
                         TRUE ~ as.character(.)))
HDI_clusters_list[[20]] %>% 
  mutate_all(~ case_when(. == 1 ~ "PLS", #paesi lento sviluppo (R1)
                         . == 2 ~ "PVS", #paesi in via di sviluppo (R4)
                         . == 3 ~ "PMR", #paesi medio reddito (R3)
                         . == 4 ~ "PE", #paesi emergenti (R2)
                         . == 5 ~ "PSA", #paesi sviluppo avanzato (R5)
                         TRUE ~ as.character(.)))
HDI_clusters_list[[21]] %>% 
  mutate_all(~ case_when(. == 1 ~ "PLS", #paesi lento sviluppo (R1)
                         . == 2 ~ "PVS", #paesi in via di sviluppo (R4)
                         . == 3 ~ "PMR", #paesi medio reddito (R3)
                         . == 4 ~ "PE", #paesi emergenti (R2)
                         . == 5 ~ "PSA", #paesi sviluppo avanzato (R5)
                         TRUE ~ as.character(.)))
HDI_clusters_list[[22]] %>% 
  mutate_all(~ case_when(. == 1 ~ "PLS", #paesi lento sviluppo (R1)
                         . == 2 ~ "PVS", #paesi in via di sviluppo (R4)
                         . == 3 ~ "PMR", #paesi medio reddito (R3)
                         . == 4 ~ "PSA", #paesi sviluppo avanzato (R5)
                         . == 5 ~ "PE", #paesi emergenti (R2)
                         TRUE ~ as.character(.)))
```

```{r}
library(dplyr)

HDI_clusters_combined <- bind_cols(HDI_clusters_list)

HDI_clusters_combined <- HDI_clusters_combined %>%
  select(-c(4,7,10,13,16,19,22,25,28,31,34,37,40,43,46,49,52,55,58,61,64))

new_names <- paste0(2000:2021)

names(HDI_clusters_combined)[grep("^Group", names(HDI_clusters_combined))] <- paste0( 2000:2021)
HDI_clusters_combined <- HDI_clusters_combined %>%
  select(-starts_with("New_Col_Name"))
HDI_clusters_combined_num <- HDI_clusters_combined%>% 
  rename_with(~ "Country", 1)

```
###Anomaly Detection HDI
```{r}
library(tidyr)
library(dplyr)

# Trasforma il dataframe in formato lungo
HDI_clusters_combined_long <- HDI_clusters_combined_num %>% 
  pivot_longer(cols = -Country, names_to = "year", values_to = "value") %>% 
  arrange(Country, year)

# Raggruppa le righe per "Country"
HDI_clusters_combined_grouped <- HDI_clusters_combined_long %>% 
  group_by(Country)

HDI_clusters_combined_diff <- HDI_clusters_combined_grouped %>% 
  mutate(diff = value - lag(value)) %>% 
  select(-value) %>% 
  ungroup()
HDI_clusters_combined_wide <- HDI_clusters_combined_diff %>% 
  pivot_wider(names_from = year, values_from = diff) %>% 
  select(Country, everything())
HDI_clusters_combined_wide <- HDI_clusters_combined_wide %>% 
  mutate_all(~ replace(., . == 0, NA))
View(HDI_clusters_combined_wide)

HDI_clusters_combined_wide_fin <- HDI_clusters_combined_wide %>% 
  mutate_all(~ifelse(. %in% c(3, 4, -3, -4),NA, .))

library(openxlsx)
write.xlsx(HDI_clusters_combined_wide_fin, "HDI_clusters_combined_wide_finale.xlsx", rowNames = FALSE)

```
#GDP_PCAP, Annual growth rate of real GDP per capita (%) 8.1.1
```{r}
library(readxl)

# Leggi il file Excel 
GDP_PCAP <- read_excel("C:/Users/39388/Downloads/dataset/NY_GDP_PCAP.xlsx")
cols_to_remove <- c("Goal", "Target", "Indicator", "SeriesCode", "SeriesDescription", 
                    "GeoAreaCode", "BasePeriod", "Source", "Units", "Observation Status", 
                    "Nature", "Reporting Type","Time_Detail")
GDP_PCAP <- GDP_PCAP[, !(names(GDP_PCAP) %in% cols_to_remove)]
head(GDP_PCAP)
sum(is.na(GDP_PCAP))

```

```{r}
# seleziona solo le righe con nomi di paese diversi da quelli specificati
GDP_PCAP <- subset(GDP_PCAP, !(GeoAreaName %in% c("Curaçao", "Sint Maarten (Dutch part)", "South Sudan", "Sudan")))
GDP_PCAP <- GDP_PCAP %>%
  filter(GeoAreaName %in% HDI_clusters_combined_num$Country)
sum(is.na(GDP_PCAP))
```



#SL_EMP_PCAP, Annual growth rate of real GDP per employed person (%) 8.2.1
```{r}
library(readxl)

# Leggi il file Excel
SL_EMP_PCAP <- read_excel("C:/Users/39388/Downloads/dataset/SL_EMP_PCAP.xlsx")
cols_to_remove <- c("Goal", "Target", "Indicator", "SeriesCode", "SeriesDescription", 
                    "GeoAreaCode", "BasePeriod", "Source", "Units", "Observation Status", 
                    "Nature", "Reporting Type","Time_Detail")
SL_EMP_PCAP <- SL_EMP_PCAP[, !(names(SL_EMP_PCAP) %in% cols_to_remove)]
head(SL_EMP_PCAP)
SL_EMP_PCAP <- SL_EMP_PCAP %>%
  filter(GeoAreaName %in% HDI_clusters_combined_num$Country)
sum(is.na(SL_EMP_PCAP))

```

```{r}
SL_EMP_PCAP <- subset(SL_EMP_PCAP, !(GeoAreaName %in% c("Curaçao", "Sint Maarten (Dutch part)", "South Sudan", "Sudan")))
```

```{r}


# Confronto dei nomi delle righe
diff_gdp_sl <- setdiff(GDP_PCAP$GeoAreaName, SL_EMP_PCAP$GeoAreaName)
diff_sl_gdp <- setdiff(SL_EMP_PCAP$GeoAreaName, GDP_PCAP$GeoAreaName)



GDP_PCAP <- subset(GDP_PCAP, !(GeoAreaName %in% diff_gdp_sl))
SL_EMP_PCAP <- subset(SL_EMP_PCAP, !(GeoAreaName %in% diff_sl_gdp))
SL_EMP_PCAP$GeoAreaName
```

###Confronto SL_PCAP e GDP_PCAP
```{r}
GDP_PCAP_clean <- GDP_PCAP[, -1]
SL_EMP_PCAP_clean <- SL_EMP_PCAP[, -c(1, ncol(SL_EMP_PCAP))]

GDP_PCAP_clean[] <- lapply(GDP_PCAP_clean, as.numeric)
SL_EMP_PCAP_clean[] <- lapply(SL_EMP_PCAP_clean, as.numeric)
diff <- SL_EMP_PCAP_clean - GDP_PCAP_clean
# Esporta il dataset "diff" in formato Excel
write.table(diff, "diff1.xls", sep="\t", quote=FALSE)
SL_EMP_PCAP$GeoAreaName
write.table(SL_EMP_PCAP$GeoAreaName, "geo.xls", sep="\t", quote=FALSE)

```
Se il tasso di crescita del PIL pro capite è maggiore del tasso di crescita del PIL per persona impiegata, questo potrebbe indicare che il paese sta generando nuovi posti di lavoro, ma che il reddito medio per lavoratore non sta aumentando molto velocemente. D'altra parte, se il tasso di crescita del PIL per persona impiegata è maggiore del tasso di crescita del PIL pro capite, questo potrebbe indicare che il paese sta migliorando la produttività del lavoro e l'efficienza economica, ma che la crescita della popolazione potrebbe limitare la crescita del PIL pro capite.

se il tasso di crescita del PIL pro capite è costantemente maggiore del tasso di crescita del PIL per persona impiegata, potrebbe indicare che il paese sta investendo nella creazione di nuovi posti di lavoro, ma il reddito medio per lavoratore non sta aumentando molto velocemente. In questo caso, il paese potrebbe avere un alto tasso di disoccupazione o lavoratori che sono sottopagati rispetto alla media globale.

D'altra parte, se il tasso di crescita del PIL per persona impiegata è costantemente maggiore del tasso di crescita del PIL pro capite, potrebbe indicare che il paese sta migliorando la produttività del lavoro e l'efficienza economica, ma la crescita della popolazione potrebbe limitare la crescita del PIL pro capite
#GDP
```{r}
library(readr)
library(dplyr)
library(tidyr)
GDP <- read_csv("C:/Users/39388/Downloads/gdp-per-person-employed-constant-ppp.csv")
GDP <- GDP %>% 
  rename(GDPPPE = `GDP per person employed (constant 2017 PPP $)`) %>% 
  select(-Code)
GDP <- GDP %>%
  dplyr::filter(Year >= 2000) %>%
  group_by(Entity, Year) %>%
  summarize(GDPPPE=mean(GDPPPE, na.rm = TRUE)) %>%
  pivot_wider(names_from = Year, values_from = GDPPPE)

GDP <- GDP %>%
  select(Entity, `2000`, `2001`, `2002`, `2003`, `2004`, `2005`, `2006`, `2007`, `2008`, `2009`, `2010`, `2011`, `2012`, `2013`, `2014`, `2015`, `2016`, `2017`, `2018`, `2019`, `2020`)

GDP <- GDP %>% rename(GeoAreaName = Entity)
GDP <- GDP %>%
  filter(GeoAreaName %in% SL_EMP_PCAP$GeoAreaName)
sum(is.na(GDP))
library(dplyr)
valore_max <- max(unlist(GDP[, -c(1)]), na.rm = TRUE)
valore_min <- min(unlist(GDP[, -c(1)]), na.rm = TRUE)

indicatore_GDP <- GDP %>% 
  mutate_all(~ (log(.) - log(valore_min))/(log(valore_max)-log(valore_min)))
```

```{r}
require(cluster)
require(factoextra)
indicatore_GDP <- indicatore_GDP %>% 
  select(`2000`:`2020`)
indicatore_GDP=na.omit(indicatore_GDP)
indicatore_GDP=na.omit(indicatore_GDP)
set.seed(123)
indicatore_GDP <- indicatore_GDP[,2:22]
k <- 4 # Numero di cluster da esplorare
sil <- silhouette(kmeans(indicatore_GDP, k)$cluster, dist(indicatore_GDP))
plot(sil)

# Esegui l'analisi cluster con il metodo di clustering gerarchico
indicatore_GDP_dist <- dist(indicatore_GDP, method = "euclidean")
indicatore_GDP_hclust <- hclust(indicatore_GDP_dist, method = "ward.D2")
# Suddividi i paesi in 3 gruppi
indicatore_GDP_groups <- cutree(indicatore_GDP_hclust, k = k)

# Aggiungi la colonna dei gruppi al dataframe originale
indicatore_GDP_final <- cbind(indicatore_GDP, Group = indicatore_GDP_groups)
```

```{r}
# Visualizza il dendrogramma
fviz_dend(indicatore_GDP_hclust, k = k)

# Visualizza i cluster in uno spazio bidimensionale
HDI_pca <- prcomp(indicatore_GDP)
fviz_cluster(list(data = HDI_pca$x[,1:2], cluster = indicatore_GDP_groups), 
             geom = "point", 
             palette = "jco",
             ggtheme = theme_classic()) + 
  ggtitle("Clustering gerarchico (Ward.D2) dei paesi") + 
  theme(plot.title = element_text(hjust = 0.5))
```

```{r}
indicatore_GDP_means <- rowMeans(indicatore_GDP[, 2:(ncol(indicatore_GDP)-1)], na.rm = TRUE)
indicatore_GDP_with_means <- cbind(indicatore_GDP_final, indicatore_GDP_means)
names(indicatore_GDP_with_means)[ncol(indicatore_GDP_with_means)] <- "media"
indicatore_GDP_means <- indicatore_GDP_with_means %>%
  group_by(Group) %>%
  summarize(mean_media = mean(media, na.rm = TRUE))
indicatore_GDP_group_rank <- indicatore_GDP_means %>%
  mutate(rank = min_rank(mean_media)) %>%
  arrange(mean_media)
indicatore_GDP_df_labed <- indicatore_GDP_final %>% 
  mutate_all(~ case_when(. == 1 ~ "PMBR", #paesi medio basso reddito
                         . == 2 ~ "PMAR", #paesi medio alto reddito
                         . == 3 ~ "PRA", #paesi alto reddito
                         . == 4 ~ "PRB", #paesi basso reddito 
                         TRUE ~ as.character(.)))
```

```{r}
GDP <- na.omit(GDP)

indicatore_GDP_final <- cbind(GDP[,1], indicatore_GDP_final)
# Utilizza la funzione unique() per ottenere l'elenco dei gruppi presenti nel dataset
elenco_gruppi <- unique(indicatore_GDP_final$Group)
# Calcola la media dei valori per riga
indicatore_GDP_final$MediaRiga <- rowMeans(indicatore_GDP_final[, -c(1,20)])

# Per ogni gruppo, stampa l'elenco dei paesi corrispondenti e calcola la media dei valori per ogni paese
for (gruppo in elenco_gruppi) {
  paesi <- indicatore_GDP_final$GeoAreaName[indicatore_GDP_final$Group == gruppo]
  cat("Gruppo:", gruppo, "\n")
  cat("Paesi:", paste(paesi, collapse = ", "), "\n\n")
  
  for (paese in paesi) {
    media_valori <- mean(indicatore_GDP_final$MediaRiga[indicatore_GDP_final$Group == gruppo & indicatore_GDP_final$GeoAreaName == paese])
    cat("Paese:", paese, "- Media della riga:", media_valori, "\n")
  }
  
  media_valori_gruppo <- mean(indicatore_GDP_final$MediaRiga[indicatore_GDP_final$Group == gruppo])
  cat("Media dei valori per gruppo:", media_valori_gruppo, "\n\n")
}



```

```{r}

  
# Trasforma il dataframe in formato "long"
indicatore_GDP_final_long <- gather(indicatore_GDP_final, key = "anno", value = "valore", -c("GeoAreaName", "Group"))

# Converti la colonna "anno" in un valore numerico
indicatore_GDP_final_long$anno <- as.numeric(indicatore_GDP_final_long$anno)
indicatore_GDP_final_long <- cbind(indicatore_GDP[,1], indicatore_GDP_final_long)

# Crea il grafico utilizzando la colonna "anno" come asse x
ggplot(indicatore_GDP_final_long, aes(x = anno, y = valore, color = factor(Group), label = GeoAreaName)) +
  geom_point() +
  geom_text(nudge_x = 0.02, nudge_y = 0.02) +
  labs(title = "Analisi Cluster del Reddito per Paese",
       x = "Anno",
       y = "Valore del Reddito",
       color = "Gruppo") +
  scale_color_discrete(name = "Gruppo", labels = c("Gruppo 1", "Gruppo 2", "Gruppo 3", "Gruppo 4", "Gruppo 5")) +
  theme_bw()
```

```{r}
library(ggplot2)
library(dplyr)

# Filtra le righe per l'anno 2006
indicatore_GDP_final_long <- indicatore_GDP_final_long %>% 
  filter(anno == 2001)

# Crea il grafico utilizzando la colonna "Entity" come etichetta sull'asse x
ggplot(indicatore_GDP_final_long, aes(x = GeoAreaName, y = valore, color = factor(Group))) +
  geom_point() +
  labs(title = "Analisi Cluster dell'HDI per Paese (anno 2001)",
       x = "Paese",
       y = "Valore del Reddito",
       color = "Gruppo") +
  scale_color_discrete(name = "Gruppo", labels = c("Gruppo 1", "Gruppo 2", "Gruppo 3", "Gruppo 4", "Gruppo 5")) +
  coord_flip() +
  theme_bw()
```

#EN_MAT_DOMCMPC,Domestic material consumption per capita, by type of raw material (tonnes) 8.4.2
```{r}
library(readxl)

# Leggi il file Excel e seleziona fino alla riga 417
EN_MAT_DOMCMPC <- read_excel("C:/Users/39388/Downloads/dataset/EN_MAT_DOMCMPC.xlsx")
cols_to_remove <- c("Goal", "Target", "Indicator", "SeriesCode", "SeriesDescription", 
                    "GeoAreaCode", "BasePeriod", "Source", "Units", "Observation Status", 
                    "Nature", "Reporting Type","Time_Detail")
EN_MAT_DOMCMPC <- EN_MAT_DOMCMPC[, !(names(EN_MAT_DOMCMPC) %in% cols_to_remove)]
EN_MAT_DOMCMPC <- EN_MAT_DOMCMPC %>%
  filter(GeoAreaName %in% SL_EMP_PCAP$GeoAreaName)
sum(is.na(EN_MAT_DOMCMPC))
```
```{r}
split_data <- split(EN_MAT_DOMCMPC, EN_MAT_DOMCMPC$`Type of product`)
types_of_product <- unique(EN_MAT_DOMCMPC$`Type of product`)
split_data <- lapply(split_data, function(df) {
  # Verifica quali nomi nella colonna GeoAreaName si ripetono
  duplicate_names <- duplicated(df$GeoAreaName)
  
  if (any(duplicate_names)) {
    # Elimina i duplicati
    df <- unique(df, by = "GeoAreaName")
  }
  
  return(df)
})
split_data_EN_MAT_DOMCMPC <- lapply(split_data, function(df) {
  df %>%
    filter(GeoAreaName %in% split_data$COL$GeoAreaName)
})
```


```{r}
for (i in 1:length(types_of_product)) {
  missing_values[i] <- sum(is.na(split_data[[types_of_product[i]]]))
}

types_of_product <- types_of_product[missing_values == 0]
```

```{r}
# Inizializza una lista vuota per i dati modificati
split_data_modified <- list()

# Ciclo for per iterare su ogni prodotto
for (i in 1:length(types_of_product)) {
  # Rimuovi la seconda colonna dal dataset del prodotto corrente
  split_data_modified[[types_of_product[i]]] <- split_data[[types_of_product[i]]][,-2]
}
library(dplyr)
library(tidyr)
# Inizializza una lista vuota per i dati trasposti
transposed_data <- list()

# Ciclo for per iterare su ogni prodotto
for (i in 1:length(types_of_product)) {
  # Trasponi i dati del prodotto corrente
  transposed <- as.data.frame(t(split_data_modified[[types_of_product[i]]]))
  
  # Aggiungi il dataframe alla lista
  transposed_data[[i]] <- transposed
}
# Ciclo for per iterare su ogni dataframe nella lista
for (i in 1:length(transposed_data)) {
  # Estrai il dataframe corrente
  df <- transposed_data[[i]]
  
  # Estrai i nomi della prima riga
  col_names <- as.character(df[1, ])
  
  # Assegna i nomi della prima riga come nomi delle variabili del dataframe
  colnames(df) <- col_names
  
  # Rimuovi la prima riga dal dataframe
  df <- df[-1, ]
  
  # Aggiorna il dataframe nella lista
  transposed_data[[i]] <- df
}
# Ciclo for per iterare su ogni dataframe nella lista
for (i in 1:length(transposed_data)) {
  # Estrai il dataframe corrente
  df <- transposed_data[[i]]
  
  # Trasforma i dati in numerici
  df <- sapply(df, as.numeric)
  
  # Aggiorna il dataframe nella lista
  transposed_data[[i]] <- df
  transposed_data[[i]]=as.data.frame(transposed_data[[i]])
}

# Ciclo for per iterare su ogni dataframe nella lista
for (i in 1:length(transposed_data)) {
  # Estrai il dataframe corrente
  df <- transposed_data[[i]]
  
  # Aggiungi la colonna "Year" con gli anni dal 2000 al 2019
  df <- df %>%
    mutate(Year = 2000:2019) %>%
    relocate(Year, .before = 1)
  
  # Aggiorna il dataframe nella lista
  transposed_data[[i]] <- df
}

GDP_T=t(GDP)
as.data.frame(GDP_T)

# Estrai i nomi della prima riga
col_names <- as.character(GDP_T[1, ])
  
  # Assegna i nomi della prima riga come nomi delle variabili del dataframe
colnames(GDP_T) <- col_names
  # Rimuovi la prima riga dal dataframe
GDP_T <- GDP_T[-1, ]
GDP_T=as.data.frame(GDP_T)

# Trasforma i dati in numerici
GDP_T <- sapply(GDP_T[-1], as.numeric)
GDP_T <- head(GDP_T, n = nrow(GDP_T) - 1)

GDP_T=as.data.frame(GDP_T)
# Aggiungi la colonna "Year" con gli anni dal 2000 al 2019
GDP_T <- GDP_T %>%
  mutate(Year = 2000:2019) %>%
  relocate(Year, .before = 1)

correlation_list <- list()  # Crea una lista vuota per la correlazione
for (k in 1:length(types_of_product)) {
  # Ottieni i nomi delle colonne dal dataframe transposed_data[[k]]
  col_names <- colnames(transposed_data[[k]])
  
  # Seleziona solo le colonne di GDP_T con i nomi corrispondenti
  GDP_T_filtered <- GDP_T[, intersect(col_names, colnames(GDP_T))]
  col_names <- colnames(GDP_T)
  
  transposed_data_filtered <- transposed_data[[k]][, intersect(col_names, colnames(transposed_data[[k]]))]
  
  # Calcola la correlazione tra consumo di carbone e PIL per ogni paese
  correlation <- sapply(1:ncol(transposed_data_filtered), function(i) {
    cor(transposed_data_filtered[, i], GDP_T_filtered[, i])
  })
  
  # Crea un vettore con i nomi dei paesi
  paesi <- colnames(transposed_data_filtered)[-1]
  
  # Crea una lista temporanea per la correlazione
  temp_list <- list(paesi = paesi, correlation = correlation[-1])
  
  # Sostituisci i valori NA con 0 nella correlazione
  temp_list$correlation[is.na(temp_list$correlation)] <- 0
  
  # Aggiungi la lista temporanea alla correlazione_list
  correlation_list[[k]] <- temp_list
}



```

```{r}
types_of_product
correlation_df <- as.data.frame(correlation_list[11]) #arriva fino a 13, type of product [[2,9,10,12]]  non serve
correlation_df
# Rimuovi la riga 23 dal dataframe correlation_df
correlation_df <- correlation_df[-23, ]

# Seleziona solo le prime 20 osservazioni dal dataframe correlation_df

# Plottaggio del grafico a barre con personalizzazioni
ggplot(correlation_df[61:90,], aes(x = paesi, y = correlation)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  labs(x = "", y = "Correlazione") +
  ggtitle("Correlazione tra Petrolio e GDP") +
  theme_minimal() +
  theme(plot.title = element_text(size = 16, face = "bold"),
        axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5, size = 12),
        axis.text.y = element_text(size = 12),
        axis.title = element_text(size = 14, face = "bold"),
        panel.grid.major.y = element_blank(),
        panel.grid.minor = element_blank(),
        panel.border = element_blank(),
        plot.margin = unit(c(2, 10, 2, 2), "lines"))


```

#ST_GDP_ZS,Tourism direct GDP as a proportion of total GDP
```{r}
library(readxl)

# Leggi il file Excel e seleziona fino alla riga 417
ST_GDP_ZS <- read_excel("C:/Users/39388/Downloads/dataset/ST_GDP_ZS.xlsx")
cols_to_remove <- c("Goal", "Target", "Indicator", "SeriesCode", "SeriesDescription", 
                    "GeoAreaCode", "BasePeriod", "Source", "Units", "Observation Status", 
                    "Nature", "Reporting Type","Time_Detail")
ST_GDP_ZS <- ST_GDP_ZS[, !(names(ST_GDP_ZS) %in% cols_to_remove)]
ST_GDP_ZS <- ST_GDP_ZS %>%
  filter(GeoAreaName %in% SL_EMP_PCAP$GeoAreaName)
sum(is.na(ST_GDP_ZS))

```

```{r}

group_1 <- c("Bangladesh", "Benin", "Burkina Faso", "Burundi", "Cambodia", "Cameroon", "Central African Republic", "Chad", "China",
             "Comoros", "Congo", "Ethiopia", "Gambia", "Ghana", "Guinea", "Haiti", "Honduras", "India", "Kenya", "Kyrgyzstan", "Lesotho",
             "Liberia", "Madagascar", "Malawi", "Mali", "Mozambique", "Myanmar", "Nepal", "Nicaragua", "Niger", "Pakistan", "Papua New Guinea",
             "Rwanda", "Senegal", "Sierra Leone", "Solomon Islands", "Tajikistan", "Togo", "Uganda", "Uzbekistan", "Zambia", "Zimbabwe")

group_2 <- c("Albania", "Angola", "Armenia", "Azerbaijan", "Barbados", "Belarus", "Belize", "Brazil", "Colombia", "Dominican Republic",
             "Ecuador", "Egypt", "El Salvador", "Eswatini", "Fiji", "Georgia", "Guatemala", "Guyana", "Indonesia", "Jamaica", "Mauritania",
             "Mongolia", "Morocco", "Namibia", "Paraguay", "Peru", "Philippines", "Saint Lucia", "Saint Vincent and the Grenadines", "Samoa",
             "Sri Lanka", "Thailand", "Tonga", "Tunisia", "Ukraine", "World")
group_3 <- c("Algeria", "Argentina", "Bosnia and Herzegovina", "Botswana", "Bulgaria", "Chile", "Costa Rica", "Croatia", "Cyprus",
             "Czechia", "Estonia", "Gabon", "Hungary", "Iraq", "Jordan", "Kazakhstan", "Latvia", "Libya", "Lithuania", "Malaysia",
             "Maldives", "Mauritius", "Mexico", "North Macedonia", "Panama", "Poland", "Portugal", "Romania", "Serbia", "Slovakia",
             "Slovenia", "South Africa", "Trinidad and Tobago", "Uruguay")
group_4 <- c("Australia", "Austria", "Bahamas", "Bahrain", "Belgium", "Canada", "Denmark", "Equatorial Guinea", "Finland", "France",
             "Germany", "Greece", "Iceland", "Ireland", "Israel", "Italy", "Japan", "Kuwait", "Luxembourg", "Malta", "Netherlands",
             "New Zealand", "Norway", "Oman", "Qatar", "Saudi Arabia", "Singapore", "Spain", "Sweden", "Switzerland", "United Arab Emirates")

# Creazione del dataset per il Gruppo 1
group_1_dataset <- ST_GDP_ZS[ST_GDP_ZS$GeoAreaName %in% group_1, ]
# Creazione del dataset per il Gruppo 2
group_2_dataset <- ST_GDP_ZS[ST_GDP_ZS$GeoAreaName %in% group_2, ]
# Creazione del dataset per il Gruppo 3
group_3_dataset <- ST_GDP_ZS[ST_GDP_ZS$GeoAreaName %in% group_3, ]
# Creazione del dataset per il Gruppo 4
group_4_dataset <- ST_GDP_ZS[ST_GDP_ZS$GeoAreaName %in% group_4, ]
```

```{r}
# Conversione delle colonne in numeri
group_4_dataset[, -(1)] <- sapply(group_4_dataset[, -(1)], as.numeric)
percent_changes <- apply(group_4_dataset[, -(1)], 1, function(x) {
  percent_change <- c(NA, diff(rev(x)) / rev(x[-1])) * 100
  percent_change <- rev(percent_change)
  percent_change
})

percent_changes <- t(percent_changes)

as.data.frame(percent_changes)

# Calcolo della media con peso minore per i valori anomali
weighted_avg <- apply(percent_changes, 2, function(x) weighted.mean(x, 1 - is.na(x)))

# Visualizzazione dei risultati
print(weighted_avg)
group_4_dataset_new <- group_4_dataset %>%
  select(-c(GeoAreaName))
weighted_avg=as.data.frame(weighted_avg)
for (i in (ncol(group_4_dataset_new)-1):1) {
  for (j in nrow(group_4_dataset_new):1) {
    if (is.na(group_4_dataset_new[j, i])) {
      group_4_dataset_new[j, i] <- group_4_dataset_new[j, i+1]*(1+weighted_avg[i,1]/100)
    }
  }
}
# Calcolo della variazione percentuale per ogni riga
percent_changes2 <- apply(group_4_dataset[, -(1)], 1, function(x) {
  percent_change <- c(NA, diff(x) / lag(x[-1], default = x[1])) * 100
  percent_change
})
percent_changes2 <- t(percent_changes2)

as.data.frame(percent_changes)
# Calcolo della media con peso minore per i valori anomali
weighted_avg2 <- apply(percent_changes2, 2, function(x) weighted.mean(x, 1 - is.na(x)))
group_4_dataset_new2 <- group_4_dataset_new 
weighted_avg2=as.data.frame(weighted_avg2)
for (i in (ncol(group_4_dataset_new2)):2) {
  for (j in (nrow(group_4_dataset_new2)):1) {
    if (is.na(group_4_dataset_new2[j, i])) {
      group_4_dataset_new2[j, i] <- group_4_dataset_new2[j, i-1]*(1+weighted_avg2[i,1]/100)
    }
  }
}
group_4_dataset_new[, ncol(group_4_dataset_new)] <- group_4_dataset_new2[, (ncol(group_4_dataset_new2))]
group_4_dataset_new <- cbind(group_4_dataset[, 1], group_4_dataset_new)# Rimuovi le ultime due colonne
group_4_dataset_new <- group_4_dataset_new[, -c(14,15)]

# Conta i valori mancanti per ogni riga
missing_values <- apply(group_4_dataset_new, 1, function(x) sum(is.na(x)))

# Seleziona solo le righe con al massimo due valori mancanti
group_4_dataset_new <- group_4_dataset_new[missing_values <= 2, ]
# Controlla se ci sono dati mancanti nel dataframe
if (anyNA(group_4_dataset_new)) {
  print("Il dataframe contiene dati mancanti.")
} else {
  print("Il dataframe non contiene dati mancanti.")
}

```
```{r}
library(zoo)
# Conversione delle colonne in numeri
group_3_dataset[, -(1)] <- sapply(group_3_dataset[, -(1)], as.numeric)
percent_changes <- apply(group_3_dataset[, -(1:2)], 1, function(x) {
  percent_change <- c(NA, diff(rev(x)) / rev(x[-1])) * 100
  percent_change <- rev(percent_change)
  percent_change
})

percent_changes <- t(percent_changes)

as.data.frame(percent_changes)

# Calcolo della media con peso minore per i valori anomali
weighted_avg <- apply(percent_changes, 2, function(x) weighted.mean(x, 1 - is.na(x)))

# Visualizzazione dei risultati
print(weighted_avg)
group_3_dataset_new <- group_3_dataset %>%
  select(-c(GeoAreaName))
weighted_avg=as.data.frame(weighted_avg)
for (i in (ncol(group_3_dataset_new)-1):1) {
  for (j in nrow(group_3_dataset_new):1) {
    if (is.na(group_3_dataset_new[j, i])) {
      group_3_dataset_new[j, i] <- group_3_dataset_new[j, i+1]*(1+weighted_avg[i,1]/100)
    }
  }
}
# Calcolo della variazione percentuale per ogni riga
percent_changes2 <- apply(group_3_dataset[, -(1:2)], 1, function(x) {
  percent_change <- c(NA, diff(x) / lag(x[-1], default = x[1])) * 100
  percent_change
})
percent_changes2 <- t(percent_changes2)

as.data.frame(percent_changes)
# Calcolo della media con peso minore per i valori anomali
weighted_avg2 <- apply(percent_changes2, 2, function(x) weighted.mean(x, 1 - is.na(x)))
group_3_dataset_new2 <- group_3_dataset %>%
  select(-c(GeoAreaName))
weighted_avg2=as.data.frame(weighted_avg2)
for (i in (ncol(group_3_dataset_new2)):2) {
  for (j in nrow(group_3_dataset_new2):1) {
    if (is.na(group_3_dataset_new2[j, i])) {
      group_3_dataset_new2[j, i] <- group_3_dataset_new2[j, i-1]*(1+weighted_avg2[i,1]/100)
    }
  }
}
group_3_dataset_new[, ncol(group_3_dataset_new)] <- group_3_dataset_new2[, ncol(group_3_dataset_new2)]
group_3_dataset_new <- cbind(group_3_dataset[, 1], group_3_dataset_new)
group_3_dataset_new <- group_3_dataset_new[, -c(14,15)]

# Conta i valori mancanti per ogni riga
missing_values <- apply(group_3_dataset_new, 1, function(x) sum(is.na(x)))

# Seleziona solo le righe con al massimo due valori mancanti
group_3_dataset_new <- group_3_dataset_new[missing_values <= 2, ]
group_3_dataset_new <- na.locf(group_3_dataset_new, na.rm = FALSE, fromLast = FALSE)

```

```{r}
# Conversione delle colonne in numeri
group_2_dataset[, -(1)] <- sapply(group_2_dataset[, -(1)], as.numeric)
percent_changes <- apply(group_2_dataset[, -(1:2)], 1, function(x) {
  percent_change <- c(NA, diff(rev(x)) / rev(x[-1])) * 100
  percent_change <- rev(percent_change)
  percent_change
})

percent_changes <- t(percent_changes)

as.data.frame(percent_changes)

# Calcolo della media con peso minore per i valori anomali
weighted_avg <- apply(percent_changes, 2, function(x) weighted.mean(x, 1 - is.na(x)))

# Visualizzazione dei risultati
print(weighted_avg)
group_2_dataset_new <- group_2_dataset %>%
  select(-c(GeoAreaName))
weighted_avg=as.data.frame(weighted_avg)
for (i in (ncol(group_2_dataset_new)-1):1) {
  for (j in nrow(group_2_dataset_new):1) {
    if (is.na(group_2_dataset_new[j, i])) {
      group_2_dataset_new[j, i] <- group_2_dataset_new[j, i+1]*(1+weighted_avg[i,1]/100)
    }
  }
}
# Calcolo della variazione percentuale per ogni riga
percent_changes2 <- apply(group_2_dataset[, -(1:2)], 1, function(x) {
  percent_change <- c(NA, diff(x) / lag(x[-1], default = x[1])) * 100
  percent_change
})
percent_changes2 <- t(percent_changes2)

as.data.frame(percent_changes)
# Calcolo della media con peso minore per i valori anomali
weighted_avg2 <- apply(percent_changes2, 2, function(x) weighted.mean(x, 1 - is.na(x)))
group_2_dataset_new2 <- group_2_dataset %>%
  select(-c(GeoAreaName))
weighted_avg2=as.data.frame(weighted_avg2)
for (i in (ncol(group_2_dataset_new2)):2) {
  for (j in nrow(group_2_dataset_new2):1) {
    if (is.na(group_2_dataset_new2[j, i])) {
      group_2_dataset_new2[j, i] <- group_2_dataset_new2[j, i-1]*(1+weighted_avg2[i,1]/100)
    }
  }
}
group_2_dataset_new[, ncol(group_2_dataset_new)] <- group_2_dataset_new2[, ncol(group_2_dataset_new2)]
group_2_dataset_new <- cbind(group_2_dataset[, 1], group_2_dataset_new)
group_2_dataset_new <- group_2_dataset_new[, -c(14,15)]

# Conta i valori mancanti per ogni riga
missing_values <- apply(group_2_dataset_new, 1, function(x) sum(is.na(x)))

# Seleziona solo le righe con al massimo due valori mancanti
group_2_dataset_new <- group_2_dataset_new[missing_values <= 2, ]

# Sostituisci i valori mancanti con il valore alla sinistra
group_2_dataset_new <- na.locf(group_2_dataset_new, na.rm = FALSE, fromLast = FALSE)
# Controlla se ci sono dati mancanti nel dataframe

```

```{r}
# Conversione delle colonne in numeri
group_1_dataset[, -(1)] <- sapply(group_1_dataset[, -(1)], as.numeric)
percent_changes <- apply(group_1_dataset[, -(1:2)], 1, function(x) {
  percent_change <- c(NA, diff(rev(x)) / rev(x[-1])) * 100
  percent_change <- rev(percent_change)
  percent_change
})

percent_changes <- t(percent_changes)

as.data.frame(percent_changes)

# Calcolo della media con peso minore per i valori anomali
weighted_avg <- apply(percent_changes, 2, function(x) weighted.mean(x, 1 - is.na(x)))

# Visualizzazione dei risultati
print(weighted_avg)
group_1_dataset_new <- group_1_dataset %>%
  select(-c(GeoAreaName))
weighted_avg=as.data.frame(weighted_avg)
for (i in (ncol(group_1_dataset_new)-1):1) {
  for (j in nrow(group_1_dataset_new):1) {
    if (is.na(group_1_dataset_new[j, i])) {
      group_1_dataset_new[j, i] <- group_1_dataset_new[j, i+1]*(1+weighted_avg[i,1]/100)
    }
  }
}
# Calcolo della variazione percentuale per ogni riga
percent_changes2 <- apply(group_1_dataset[, -(1:2)], 1, function(x) {
  percent_change <- c(NA, diff(x) / lag(x[-1], default = x[1])) * 100
  percent_change
})
percent_changes2 <- t(percent_changes2)

as.data.frame(percent_changes)
# Calcolo della media con peso minore per i valori anomali
weighted_avg2 <- apply(percent_changes2, 2, function(x) weighted.mean(x, 1 - is.na(x)))
group_1_dataset_new2 <- group_1_dataset %>%
  select(-c(GeoAreaName))
weighted_avg2=as.data.frame(weighted_avg2)
for (i in (ncol(group_1_dataset_new2)):2) {
  for (j in nrow(group_1_dataset_new2):1) {
    if (is.na(group_1_dataset_new2[j, i])) {
      group_1_dataset_new2[j, i] <- group_1_dataset_new2[j, i-1]*(1+weighted_avg2[i,1]/100)
    }
  }
}
group_1_dataset_new[, ncol(group_1_dataset_new)] <- group_1_dataset_new2[, ncol(group_1_dataset_new2)]
group_1_dataset_new <- cbind(group_1_dataset[, 1], group_1_dataset_new)
group_1_dataset_new <- group_1_dataset_new[, -c(14,15)]

# Conta i valori mancanti per ogni riga
missing_values <- apply(group_1_dataset_new, 1, function(x) sum(is.na(x)))

# Seleziona solo le righe con al massimo due valori mancanti
group_1_dataset_new <- group_1_dataset_new[missing_values <= 2, ]
for (i in 2:ncol(group_1_dataset_new)) {
  for (j in 1:nrow(group_1_dataset_new)) {
    if (is.na(group_1_dataset_new[j, i])) {
      group_1_dataset_new[j, i] <- group_1_dataset_new[j, i - 1]
    }
  }
}
if (anyNA(group_1_dataset_new)) {
  print("Il dataframe contiene dati mancanti.")
} else {
  print("Il dataframe non contiene dati mancanti.")
}
```

```{r}
library(dplyr)

turism_dataset <- rbind(group_1_dataset_new, group_2_dataset_new, group_3_dataset_new, group_4_dataset_new)

turism_dataset <- turism_dataset %>%
  arrange(GeoAreaName)
```

i dati mancanti sono stati imputati in questo modo: non siamo riusciti ad applicare tecniche di interpolazione bidimensionali(diciamo la cui formula agisce su un piano 3D)dovendo considerare sia il trend del tempo che i valori dei singoli paesi.
Abbiamo quindi innanzitutto diviso i paesi secondo la suddivisione data dal cluster del GDP per prendere i valori "piu' simili", quindi calcoliamo la variazione % anno per anno pesata per tenere a bada eventuali valori mancanti e farci un idea della tendenza annuale, in caso di eventuali valori mancanti viene quindi preso il valore precedente e moltiplicato per il tasso di variazione % rispetto all'anno successivo




#FB_ATM_TOTL, Number of automated teller machines (ATMs) per 100 000 adults
```{r}
library(readxl)

# Leggi il file Excel e seleziona fino alla riga 417
FB_ATM_TOTL <- read_excel("C:/Users/39388/Downloads/dataset/FB_ATM_TOTL.xlsx")
cols_to_remove <- c("Goal", "Target", "Indicator", "SeriesCode", "SeriesDescription", 
                    "GeoAreaCode", "BasePeriod", "Source", "Units", "Observation Status", 
                    "Nature", "Reporting Type","Time_Detail")
FB_ATM_TOTL <- FB_ATM_TOTL[, !(names(FB_ATM_TOTL) %in% cols_to_remove)]
FB_ATM_TOTL <- FB_ATM_TOTL %>%
  filter(GeoAreaName %in% SL_EMP_PCAP$GeoAreaName)
sum(is.na(FB_ATM_TOTL))
```

```{r}
group_1 <- c("Bangladesh", "Benin", "Burkina Faso", "Burundi", "Cambodia", "Cameroon", "Central African Republic", "Chad", "China",
             "Comoros", "Congo", "Ethiopia", "Gambia", "Ghana", "Guinea", "Haiti", "Honduras", "India", "Kenya", "Kyrgyzstan", "Lesotho",
             "Liberia", "Madagascar", "Malawi", "Mali", "Mozambique", "Myanmar", "Nepal", "Nicaragua", "Niger", "Pakistan", "Papua New Guinea",
             "Rwanda", "Senegal", "Sierra Leone", "Solomon Islands", "Tajikistan", "Togo", "Uganda", "Uzbekistan", "Zambia", "Zimbabwe")

group_2 <- c("Albania", "Angola", "Armenia", "Azerbaijan", "Barbados", "Belarus", "Belize", "Brazil", "Colombia", "Dominican Republic",
             "Ecuador", "Egypt", "El Salvador", "Eswatini", "Fiji", "Georgia", "Guatemala", "Guyana", "Indonesia", "Jamaica", "Mauritania",
             "Mongolia", "Morocco", "Namibia", "Paraguay", "Peru", "Philippines", "Saint Lucia", "Saint Vincent and the Grenadines", "Samoa",
             "Sri Lanka", "Thailand", "Tonga", "Tunisia", "Ukraine", "World")
group_3 <- c("Algeria", "Argentina", "Bosnia and Herzegovina", "Botswana", "Bulgaria", "Chile", "Costa Rica", "Croatia", "Cyprus",
             "Czechia", "Estonia", "Gabon", "Hungary", "Iraq", "Jordan", "Kazakhstan", "Latvia", "Libya", "Lithuania", "Malaysia",
             "Maldives", "Mauritius", "Mexico", "North Macedonia", "Panama", "Poland", "Portugal", "Romania", "Serbia", "Slovakia",
             "Slovenia", "South Africa", "Trinidad and Tobago", "Uruguay")
group_4 <- c("Australia", "Austria", "Bahamas", "Bahrain", "Belgium", "Canada", "Denmark", "Equatorial Guinea", "Finland", "France",
             "Germany", "Greece", "Iceland", "Ireland", "Israel", "Italy", "Japan", "Kuwait", "Luxembourg", "Malta", "Netherlands",
             "New Zealand", "Norway", "Oman", "Qatar", "Saudi Arabia", "Singapore", "Spain", "Sweden", "Switzerland", "United Arab Emirates")

# Creazione del dataset per il Gruppo 1
group_1_dataset <- FB_ATM_TOTL[FB_ATM_TOTL$GeoAreaName %in% group_1, ]
# Creazione del dataset per il Gruppo 2
group_2_dataset <- FB_ATM_TOTL[FB_ATM_TOTL$GeoAreaName %in% group_2, ]
# Creazione del dataset per il Gruppo 3
group_3_dataset <- FB_ATM_TOTL[FB_ATM_TOTL$GeoAreaName %in% group_3, ]
# Creazione del dataset per il Gruppo 4
group_4_dataset <- FB_ATM_TOTL[FB_ATM_TOTL$GeoAreaName %in% group_4, ]


```

```{r}
# Conversione delle colonne in numeri
group_4_dataset[, -(1)] <- sapply(group_4_dataset[, -(1)], as.numeric)
percent_changes <- apply(group_4_dataset[, -(1:2)], 1, function(x) {
  percent_change <- c(NA, diff(rev(x)) / rev(x[-1])) * 100
  percent_change <- rev(percent_change)
  percent_change
})

percent_changes <- t(percent_changes)

as.data.frame(percent_changes)

# Calcolo della media con peso minore per i valori anomali
weighted_avg <- apply(percent_changes, 2, function(x) weighted.mean(x, 1 - is.na(x)))

# Visualizzazione dei risultati
print(weighted_avg)
group_4_dataset_new <- group_4_dataset %>%
  select(-c(GeoAreaName, Age))
weighted_avg=as.data.frame(weighted_avg)
for (i in (ncol(group_4_dataset_new)-1):1) {
  for (j in nrow(group_4_dataset_new):1) {
    if (is.na(group_4_dataset_new[j, i])) {
      group_4_dataset_new[j, i] <- group_4_dataset_new[j, i+1]*(1+weighted_avg[i,1]/100)
    }
  }
}
# Calcolo della variazione percentuale per ogni riga
percent_changes2 <- apply(group_4_dataset[, -(1:2)], 1, function(x) {
  percent_change <- c(NA, diff(x) / lag(x[-1], default = x[1])) * 100
  percent_change
})
percent_changes2 <- t(percent_changes2)

as.data.frame(percent_changes)
# Calcolo della media con peso minore per i valori anomali
weighted_avg2 <- apply(percent_changes2, 2, function(x) weighted.mean(x, 1 - is.na(x)))
group_4_dataset_new2 <- group_4_dataset %>%
  select(-c(GeoAreaName, Age))
weighted_avg2=as.data.frame(weighted_avg2)
for (i in (ncol(group_4_dataset_new2)):2) {
  for (j in nrow(group_4_dataset_new2):1) {
    if (is.na(group_4_dataset_new2[j, i])) {
      group_4_dataset_new2[j, i] <- group_4_dataset_new2[j, i-1]*(1+weighted_avg2[i,1]/100)
    }
  }
}
group_4_dataset_new[, ncol(group_4_dataset_new)] <- group_4_dataset_new2[, ncol(group_4_dataset_new2)]
group_4_dataset_new <- cbind(group_4_dataset[, 1], group_4_dataset_new)
```

```{r}

# Conversione delle colonne in numeri
group_3_dataset[, -(1)] <- sapply(group_3_dataset[, -(1)], as.numeric)
percent_changes <- apply(group_3_dataset[, -(1:2)], 1, function(x) {
  percent_change <- c(NA, diff(rev(x)) / rev(x[-1])) * 100
  percent_change <- rev(percent_change)
  percent_change
})

percent_changes <- t(percent_changes)

as.data.frame(percent_changes)

# Calcolo della media con peso minore per i valori anomali
weighted_avg <- apply(percent_changes, 2, function(x) weighted.mean(x, 1 - is.na(x)))

# Visualizzazione dei risultati
print(weighted_avg)
group_3_dataset_new <- group_3_dataset %>%
  select(-c(GeoAreaName, Age))
weighted_avg=as.data.frame(weighted_avg)
for (i in (ncol(group_3_dataset_new)-1):1) {
  for (j in nrow(group_3_dataset_new):1) {
    if (is.na(group_3_dataset_new[j, i])) {
      group_3_dataset_new[j, i] <- group_3_dataset_new[j, i+1]*(1+weighted_avg[i,1]/100)
    }
  }
}
# Calcolo della variazione percentuale per ogni riga
percent_changes2 <- apply(group_3_dataset[, -(1:2)], 1, function(x) {
  percent_change <- c(NA, diff(x) / lag(x[-1], default = x[1])) * 100
  percent_change
})
percent_changes2 <- t(percent_changes2)

as.data.frame(percent_changes)
# Calcolo della media con peso minore per i valori anomali
weighted_avg2 <- apply(percent_changes2, 2, function(x) weighted.mean(x, 1 - is.na(x)))
group_3_dataset_new2 <- group_3_dataset %>%
  select(-c(GeoAreaName, Age))
weighted_avg2=as.data.frame(weighted_avg2)
for (i in (ncol(group_3_dataset_new2)):2) {
  for (j in nrow(group_3_dataset_new2):1) {
    if (is.na(group_3_dataset_new2[j, i])) {
      group_3_dataset_new2[j, i] <- group_3_dataset_new2[j, i-1]*(1+weighted_avg2[i,1]/100)
    }
  }
}
group_3_dataset_new[, ncol(group_3_dataset_new)] <- group_3_dataset_new2[, ncol(group_3_dataset_new2)]
group_3_dataset_new <- cbind(group_3_dataset[, 1], group_3_dataset_new)

```

```{r}
# Conversione delle colonne in numeri
group_2_dataset[, -(1)] <- sapply(group_2_dataset[, -(1)], as.numeric)
percent_changes <- apply(group_2_dataset[, -(1:2)], 1, function(x) {
  percent_change <- c(NA, diff(rev(x)) / rev(x[-1])) * 100
  percent_change <- rev(percent_change)
  percent_change
})

percent_changes <- t(percent_changes)

as.data.frame(percent_changes)

# Calcolo della media con peso minore per i valori anomali
weighted_avg <- apply(percent_changes, 2, function(x) weighted.mean(x, 1 - is.na(x)))

# Visualizzazione dei risultati
print(weighted_avg)
group_2_dataset_new <- group_2_dataset %>%
  select(-c(GeoAreaName, Age))
weighted_avg=as.data.frame(weighted_avg)
for (i in (ncol(group_2_dataset_new)-1):1) {
  for (j in nrow(group_2_dataset_new):1) {
    if (is.na(group_2_dataset_new[j, i])) {
      group_2_dataset_new[j, i] <- group_2_dataset_new[j, i+1]*(1+weighted_avg[i,1]/100)
    }
  }
}
# Calcolo della variazione percentuale per ogni riga
percent_changes2 <- apply(group_2_dataset[, -(1:2)], 1, function(x) {
  percent_change <- c(NA, diff(x) / lag(x[-1], default = x[1])) * 100
  percent_change
})
percent_changes2 <- t(percent_changes2)

as.data.frame(percent_changes)
# Calcolo della media con peso minore per i valori anomali
weighted_avg2 <- apply(percent_changes2, 2, function(x) weighted.mean(x, 1 - is.na(x)))
group_2_dataset_new2 <- group_2_dataset %>%
  select(-c(GeoAreaName, Age))
weighted_avg2=as.data.frame(weighted_avg2)
for (i in (ncol(group_2_dataset_new2)):2) {
  for (j in nrow(group_2_dataset_new2):1) {
    if (is.na(group_2_dataset_new2[j, i])) {
      group_2_dataset_new2[j, i] <- group_2_dataset_new2[j, i-1]*(1+weighted_avg2[i,1]/100)
    }
  }
}
group_2_dataset_new[, ncol(group_2_dataset_new)] <- group_2_dataset_new2[, ncol(group_2_dataset_new2)]
group_2_dataset_new <- cbind(group_2_dataset[, 1], group_2_dataset_new)

```

```{r}
# Conversione delle colonne in numeri
group_1_dataset[, -(1)] <- sapply(group_1_dataset[, -(1)], as.numeric)
percent_changes <- apply(group_1_dataset[, -(1:2)], 1, function(x) {
  percent_change <- c(NA, diff(rev(x)) / rev(x[-1])) * 100
  percent_change <- rev(percent_change)
  percent_change
})

percent_changes <- t(percent_changes)

as.data.frame(percent_changes)

# Calcolo della media con peso minore per i valori anomali
weighted_avg <- apply(percent_changes, 2, function(x) weighted.mean(x, 1 - is.na(x)))

# Visualizzazione dei risultati
print(weighted_avg)
group_1_dataset_new <- group_1_dataset %>%
  select(-c(GeoAreaName, Age))
weighted_avg=as.data.frame(weighted_avg)
for (i in (ncol(group_1_dataset_new)-1):1) {
  for (j in nrow(group_1_dataset_new):1) {
    if (is.na(group_1_dataset_new[j, i])) {
      group_1_dataset_new[j, i] <- group_1_dataset_new[j, i+1]*(1+weighted_avg[i,1]/100)
    }
  }
}
# Calcolo della variazione percentuale per ogni riga
percent_changes2 <- apply(group_1_dataset[, -(1:2)], 1, function(x) {
  percent_change <- c(NA, diff(x) / lag(x[-1], default = x[1])) * 100
  percent_change
})
percent_changes2 <- t(percent_changes2)

as.data.frame(percent_changes)
# Calcolo della media con peso minore per i valori anomali
weighted_avg2 <- apply(percent_changes2, 2, function(x) weighted.mean(x, 1 - is.na(x)))
group_1_dataset_new2 <- group_1_dataset %>%
  select(-c(GeoAreaName, Age))
weighted_avg2=as.data.frame(weighted_avg2)
for (i in (ncol(group_1_dataset_new2)):2) {
  for (j in nrow(group_1_dataset_new2):1) {
    if (is.na(group_1_dataset_new2[j, i])) {
      group_1_dataset_new2[j, i] <- group_1_dataset_new2[j, i-1]*(1+weighted_avg2[i,1]/100)
    }
  }
}
group_1_dataset_new[, ncol(group_1_dataset_new)] <- group_1_dataset_new2[, ncol(group_1_dataset_new2)]
group_1_dataset_new <- cbind(group_1_dataset[, 1], group_1_dataset_new)

```

```{r}
library(dplyr)

combined_dataset <- rbind(group_1_dataset_new, group_2_dataset_new, group_3_dataset_new, group_4_dataset_new)

combined_dataset <- combined_dataset %>%
  arrange(GeoAreaName)
group_1 <- c("Bangladesh", "Benin", "Burkina Faso", "Burundi", "Cambodia", "Cameroon", "Central African Republic", "Chad", "China",
             "Comoros", "Congo", "Ethiopia", "Gambia", "Ghana", "Guinea", "Haiti", "Honduras", "India", "Kenya", "Kyrgyzstan", "Lesotho",
             "Liberia", "Madagascar", "Malawi", "Mali", "Mozambique", "Myanmar", "Nepal", "Nicaragua", "Niger", "Pakistan", "Papua New Guinea",
             "Rwanda", "Senegal", "Sierra Leone", "Solomon Islands", "Tajikistan", "Togo", "Uganda", "Uzbekistan", "Zambia", "Zimbabwe")

group_2 <- c("Albania", "Angola", "Armenia", "Azerbaijan", "Barbados", "Belarus", "Belize", "Brazil", "Colombia", "Dominican Republic",
             "Ecuador", "Egypt", "El Salvador", "Eswatini", "Fiji", "Georgia", "Guatemala", "Guyana", "Indonesia", "Jamaica", "Mauritania",
             "Mongolia", "Morocco", "Namibia", "Paraguay", "Peru", "Philippines", "Saint Lucia", "Saint Vincent and the Grenadines", "Samoa",
             "Sri Lanka", "Thailand", "Tonga", "Tunisia", "Ukraine", "World")
group_3 <- c("Algeria", "Argentina", "Bosnia and Herzegovina", "Botswana", "Bulgaria", "Chile", "Costa Rica", "Croatia", "Cyprus",
             "Czechia", "Estonia", "Gabon", "Hungary", "Iraq", "Jordan", "Kazakhstan", "Latvia", "Libya", "Lithuania", "Malaysia",
             "Maldives", "Mauritius", "Mexico", "North Macedonia", "Panama", "Poland", "Portugal", "Romania", "Serbia", "Slovakia",
             "Slovenia", "South Africa", "Trinidad and Tobago", "Uruguay")
group_4 <- c("Australia", "Austria", "Bahamas", "Bahrain", "Belgium", "Canada", "Denmark", "Equatorial Guinea", "Finland", "France",
             "Germany", "Greece", "Iceland", "Ireland", "Israel", "Italy", "Japan", "Kuwait", "Luxembourg", "Malta", "Netherlands",
             "New Zealand", "Norway", "Oman", "Qatar", "Saudi Arabia", "Singapore", "Spain", "Sweden", "Switzerland", "United Arab Emirates")


```

```{r}
library(ggplot2)

# Trasformazione del dataframe da formato wide a formato long
df_long <- tidyr::pivot_longer(combined_dataset, cols = starts_with("2"), names_to = "Year", values_to = "Value")
# Conversione del campo Year in formato numerico
df_long$Year <- as.numeric(gsub("X", "", df_long$Year))
df_long$Group=ifelse(df_long$GeoAreaName %in% group_1, "GROUP_1",
        ifelse(df_long$GeoAreaName %in% group_2, "GROUP_2",
               ifelse(df_long$GeoAreaName %in% group_3, "GROUP_3",
                      ifelse(df_long$GeoAreaName %in% group_4, "GROUP_4", ""))))

# Creazione del grafico con linee separate per ogni paese e colori basati sui gruppi
ggplot(df_long[1:630,], aes(x = Year, y = Value, color = Group, group = GeoAreaName)) +
  geom_path() +
  labs(x = "Anno", y = "Valore", color = "Gruppo") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1)) +
  scale_x_continuous(labels = function(x) as.integer(x))


```
#FB_CBK_BRCH
```{r}
library(readxl)

# Leggi il file Excel e seleziona fino alla riga 417
FB_CBK_BRCH <- read_excel("C:/Users/39388/Downloads/dataset/FB_CBK_BRCH.xlsx")
cols_to_remove <- c("Goal", "Target", "Indicator", "SeriesCode", "SeriesDescription", 
                    "GeoAreaCode", "BasePeriod", "Source", "Units", "Observation Status", 
                    "Nature", "Reporting Type","Time_Detail")
FB_CBK_BRCH <- FB_CBK_BRCH[, !(names(FB_CBK_BRCH) %in% cols_to_remove)]
FB_CBK_BRCH <- FB_CBK_BRCH %>%
  filter(GeoAreaName %in% SL_EMP_PCAP$GeoAreaName)
sum(is.na(FB_CBK_BRCH))
```

```{r}
group_1 <- c("Bangladesh", "Benin", "Burkina Faso", "Burundi", "Cambodia", "Cameroon", "Central African Republic", "Chad", "China",
             "Comoros", "Congo", "Ethiopia", "Gambia", "Ghana", "Guinea", "Haiti", "Honduras", "India", "Kenya", "Kyrgyzstan", "Lesotho",
             "Liberia", "Madagascar", "Malawi", "Mali", "Mozambique", "Myanmar", "Nepal", "Nicaragua", "Niger", "Pakistan", "Papua New Guinea",
             "Rwanda", "Senegal", "Sierra Leone", "Solomon Islands", "Tajikistan", "Togo", "Uganda", "Uzbekistan", "Zambia", "Zimbabwe")

group_2 <- c("Albania", "Angola", "Armenia", "Azerbaijan", "Barbados", "Belarus", "Belize", "Brazil", "Colombia", "Dominican Republic",
             "Ecuador", "Egypt", "El Salvador", "Eswatini", "Fiji", "Georgia", "Guatemala", "Guyana", "Indonesia", "Jamaica", "Mauritania",
             "Mongolia", "Morocco", "Namibia", "Paraguay", "Peru", "Philippines", "Saint Lucia", "Saint Vincent and the Grenadines", "Samoa",
             "Sri Lanka", "Thailand", "Tonga", "Tunisia", "Ukraine", "World")
group_3 <- c("Algeria", "Argentina", "Bosnia and Herzegovina", "Botswana", "Bulgaria", "Chile", "Costa Rica", "Croatia", "Cyprus",
             "Czechia", "Estonia", "Gabon", "Hungary", "Iraq", "Jordan", "Kazakhstan", "Latvia", "Libya", "Lithuania", "Malaysia",
             "Maldives", "Mauritius", "Mexico", "North Macedonia", "Panama", "Poland", "Portugal", "Romania", "Serbia", "Slovakia",
             "Slovenia", "South Africa", "Trinidad and Tobago", "Uruguay")
group_4 <- c("Australia", "Austria", "Bahamas", "Bahrain", "Belgium", "Canada", "Denmark", "Equatorial Guinea", "Finland", "France",
             "Germany", "Greece", "Iceland", "Ireland", "Israel", "Italy", "Japan", "Kuwait", "Luxembourg", "Malta", "Netherlands",
             "New Zealand", "Norway", "Oman", "Qatar", "Saudi Arabia", "Singapore", "Spain", "Sweden", "Switzerland", "United Arab Emirates")

# Creazione del dataset per il Gruppo 1
group_1_dataset <- FB_CBK_BRCH[FB_CBK_BRCH$GeoAreaName %in% group_1, ]
# Creazione del dataset per il Gruppo 2
group_2_dataset <- FB_CBK_BRCH[FB_CBK_BRCH$GeoAreaName %in% group_2, ]
# Creazione del dataset per il Gruppo 3
group_3_dataset <- FB_CBK_BRCH[FB_CBK_BRCH$GeoAreaName %in% group_3, ]
# Creazione del dataset per il Gruppo 4
group_4_dataset <- FB_CBK_BRCH[FB_CBK_BRCH$GeoAreaName %in% group_4, ]


```

```{r}
# Conversione delle colonne in numeri
group_4_dataset[, -(1)] <- sapply(group_4_dataset[, -(1)], as.numeric)
percent_changes <- apply(group_4_dataset[, -(1:2)], 1, function(x) {
  percent_change <- c(NA, diff(rev(x)) / rev(x[-1])) * 100
  percent_change <- rev(percent_change)
  percent_change
})

percent_changes <- t(percent_changes)

as.data.frame(percent_changes)

# Calcolo della media con peso minore per i valori anomali
weighted_avg <- apply(percent_changes, 2, function(x) weighted.mean(x, 1 - is.na(x)))

# Visualizzazione dei risultati
print(weighted_avg)
group_4_dataset_new <- group_4_dataset %>%
  select(-c(GeoAreaName, Age))
weighted_avg=as.data.frame(weighted_avg)
for (i in (ncol(group_4_dataset_new)-1):1) {
  for (j in nrow(group_4_dataset_new):1) {
    if (is.na(group_4_dataset_new[j, i])) {
      group_4_dataset_new[j, i] <- group_4_dataset_new[j, i+1]*(1+weighted_avg[i,1]/100)
    }
  }
}
# Calcolo della variazione percentuale per ogni riga
percent_changes2 <- apply(group_4_dataset[, -(1:2)], 1, function(x) {
  percent_change <- c(NA, diff(x) / lag(x[-1], default = x[1])) * 100
  percent_change
})
percent_changes2 <- t(percent_changes2)

as.data.frame(percent_changes)
# Calcolo della media con peso minore per i valori anomali
weighted_avg2 <- apply(percent_changes2, 2, function(x) weighted.mean(x, 1 - is.na(x)))
group_4_dataset_new2 <- group_4_dataset %>%
  select(-c(GeoAreaName, Age))
weighted_avg2=as.data.frame(weighted_avg2)
for (i in (ncol(group_4_dataset_new2)):2) {
  for (j in nrow(group_4_dataset_new2):1) {
    if (is.na(group_4_dataset_new2[j, i])) {
      group_4_dataset_new2[j, i] <- group_4_dataset_new2[j, i-1]*(1+weighted_avg2[i,1]/100)
    }
  }
}
group_4_dataset_new[, ncol(group_4_dataset_new)] <- group_4_dataset_new2[, ncol(group_4_dataset_new2)]
group_4_dataset_new <- cbind(group_4_dataset[, 1], group_4_dataset_new)
```

```{r}

# Conversione delle colonne in numeri
group_3_dataset[, -(1)] <- sapply(group_3_dataset[, -(1)], as.numeric)
percent_changes <- apply(group_3_dataset[, -(1:2)], 1, function(x) {
  percent_change <- c(NA, diff(rev(x)) / rev(x[-1])) * 100
  percent_change <- rev(percent_change)
  percent_change
})

percent_changes <- t(percent_changes)

as.data.frame(percent_changes)

# Calcolo della media con peso minore per i valori anomali
weighted_avg <- apply(percent_changes, 2, function(x) weighted.mean(x, 1 - is.na(x)))

# Visualizzazione dei risultati
print(weighted_avg)
group_3_dataset_new <- group_3_dataset %>%
  select(-c(GeoAreaName, Age))
weighted_avg=as.data.frame(weighted_avg)
for (i in (ncol(group_3_dataset_new)-1):1) {
  for (j in nrow(group_3_dataset_new):1) {
    if (is.na(group_3_dataset_new[j, i])) {
      group_3_dataset_new[j, i] <- group_3_dataset_new[j, i+1]*(1+weighted_avg[i,1]/100)
    }
  }
}
# Calcolo della variazione percentuale per ogni riga
percent_changes2 <- apply(group_3_dataset[, -(1:2)], 1, function(x) {
  percent_change <- c(NA, diff(x) / lag(x[-1], default = x[1])) * 100
  percent_change
})
percent_changes2 <- t(percent_changes2)

as.data.frame(percent_changes)
# Calcolo della media con peso minore per i valori anomali
weighted_avg2 <- apply(percent_changes2, 2, function(x) weighted.mean(x, 1 - is.na(x)))
group_3_dataset_new2 <- group_3_dataset %>%
  select(-c(GeoAreaName, Age))
weighted_avg2=as.data.frame(weighted_avg2)
for (i in (ncol(group_3_dataset_new2)):2) {
  for (j in nrow(group_3_dataset_new2):1) {
    if (is.na(group_3_dataset_new2[j, i])) {
      group_3_dataset_new2[j, i] <- group_3_dataset_new2[j, i-1]*(1+weighted_avg2[i,1]/100)
    }
  }
}
group_3_dataset_new[, ncol(group_3_dataset_new)] <- group_3_dataset_new2[, ncol(group_3_dataset_new2)]
group_3_dataset_new <- cbind(group_3_dataset[, 1], group_3_dataset_new)

```

```{r}
# Conversione delle colonne in numeri
group_2_dataset[, -(1)] <- sapply(group_2_dataset[, -(1)], as.numeric)
percent_changes <- apply(group_2_dataset[, -(1:2)], 1, function(x) {
  percent_change <- c(NA, diff(rev(x)) / rev(x[-1])) * 100
  percent_change <- rev(percent_change)
  percent_change
})

percent_changes <- t(percent_changes)

as.data.frame(percent_changes)

# Calcolo della media con peso minore per i valori anomali
weighted_avg <- apply(percent_changes, 2, function(x) weighted.mean(x, 1 - is.na(x)))

# Visualizzazione dei risultati
print(weighted_avg)
group_2_dataset_new <- group_2_dataset %>%
  select(-c(GeoAreaName, Age))
weighted_avg=as.data.frame(weighted_avg)
for (i in (ncol(group_2_dataset_new)-1):1) {
  for (j in nrow(group_2_dataset_new):1) {
    if (is.na(group_2_dataset_new[j, i])) {
      group_2_dataset_new[j, i] <- group_2_dataset_new[j, i+1]*(1+weighted_avg[i,1]/100)
    }
  }
}
# Calcolo della variazione percentuale per ogni riga
percent_changes2 <- apply(group_2_dataset[, -(1:2)], 1, function(x) {
  percent_change <- c(NA, diff(x) / lag(x[-1], default = x[1])) * 100
  percent_change
})
percent_changes2 <- t(percent_changes2)

as.data.frame(percent_changes)
# Calcolo della media con peso minore per i valori anomali
weighted_avg2 <- apply(percent_changes2, 2, function(x) weighted.mean(x, 1 - is.na(x)))
group_2_dataset_new2 <- group_2_dataset %>%
  select(-c(GeoAreaName, Age))
weighted_avg2=as.data.frame(weighted_avg2)
for (i in (ncol(group_2_dataset_new2)):2) {
  for (j in nrow(group_2_dataset_new2):1) {
    if (is.na(group_2_dataset_new2[j, i])) {
      group_2_dataset_new2[j, i] <- group_2_dataset_new2[j, i-1]*(1+weighted_avg2[i,1]/100)
    }
  }
}
group_2_dataset_new[, ncol(group_2_dataset_new)] <- group_2_dataset_new2[, ncol(group_2_dataset_new2)]
group_2_dataset_new <- cbind(group_2_dataset[, 1], group_2_dataset_new)

```

```{r}
# Conversione delle colonne in numeri
group_1_dataset[, -(1)] <- sapply(group_1_dataset[, -(1)], as.numeric)
percent_changes <- apply(group_1_dataset[, -(1:2)], 1, function(x) {
  percent_change <- c(NA, diff(rev(x)) / rev(x[-1])) * 100
  percent_change <- rev(percent_change)
  percent_change
})

percent_changes <- t(percent_changes)

as.data.frame(percent_changes)

# Calcolo della media con peso minore per i valori anomali
weighted_avg <- apply(percent_changes, 2, function(x) weighted.mean(x, 1 - is.na(x)))

# Visualizzazione dei risultati
print(weighted_avg)
group_1_dataset_new <- group_1_dataset %>%
  select(-c(GeoAreaName, Age))
weighted_avg=as.data.frame(weighted_avg)
for (i in (ncol(group_1_dataset_new)-1):1) {
  for (j in nrow(group_1_dataset_new):1) {
    if (is.na(group_1_dataset_new[j, i])) {
      group_1_dataset_new[j, i] <- group_1_dataset_new[j, i+1]*(1+weighted_avg[i,1]/100)
    }
  }
}
# Calcolo della variazione percentuale per ogni riga
percent_changes2 <- apply(group_1_dataset[, -(1:2)], 1, function(x) {
  percent_change <- c(NA, diff(x) / lag(x[-1], default = x[1])) * 100
  percent_change
})
percent_changes2 <- t(percent_changes2)

as.data.frame(percent_changes)
# Calcolo della media con peso minore per i valori anomali
weighted_avg2 <- apply(percent_changes2, 2, function(x) weighted.mean(x, 1 - is.na(x)))
group_1_dataset_new2 <- group_1_dataset %>%
  select(-c(GeoAreaName, Age))
weighted_avg2=as.data.frame(weighted_avg2)
for (i in (ncol(group_1_dataset_new2)):2) {
  for (j in nrow(group_1_dataset_new2):1) {
    if (is.na(group_1_dataset_new2[j, i])) {
      group_1_dataset_new2[j, i] <- group_1_dataset_new2[j, i-1]*(1+weighted_avg2[i,1]/100)
    }
  }
}
group_1_dataset_new[, ncol(group_1_dataset_new)] <- group_1_dataset_new2[, ncol(group_1_dataset_new2)]
group_1_dataset_new <- cbind(group_1_dataset[, 1], group_1_dataset_new)

```

```{r}
library(dplyr)

combined_dataset <- rbind(group_1_dataset_new, group_2_dataset_new, group_3_dataset_new, group_4_dataset_new)

combined_dataset <- combined_dataset %>%
  arrange(GeoAreaName)
#Commercial bank branches (per 100000 adults)
group_1 <- c("Bangladesh", "Benin", "Burkina Faso", "Burundi", "Cambodia", "Cameroon", "Central African Republic", "Chad", "China",
             "Comoros", "Congo", "Ethiopia", "Gambia", "Ghana", "Guinea", "Haiti", "Honduras", "India", "Kenya", "Kyrgyzstan", "Lesotho",
             "Liberia", "Madagascar", "Malawi", "Mali", "Mozambique", "Myanmar", "Nepal", "Nicaragua", "Niger", "Pakistan", "Papua New Guinea",
             "Rwanda", "Senegal", "Sierra Leone", "Solomon Islands", "Tajikistan", "Togo", "Uganda", "Uzbekistan", "Zambia", "Zimbabwe")

group_2 <- c("Albania", "Angola", "Armenia", "Azerbaijan", "Barbados", "Belarus", "Belize", "Brazil", "Colombia", "Dominican Republic",
             "Ecuador", "Egypt", "El Salvador", "Eswatini", "Fiji", "Georgia", "Guatemala", "Guyana", "Indonesia", "Jamaica", "Mauritania",
             "Mongolia", "Morocco", "Namibia", "Paraguay", "Peru", "Philippines", "Saint Lucia", "Saint Vincent and the Grenadines", "Samoa",
             "Sri Lanka", "Thailand", "Tonga", "Tunisia", "Ukraine", "World")
group_3 <- c("Algeria", "Argentina", "Bosnia and Herzegovina", "Botswana", "Bulgaria", "Chile", "Costa Rica", "Croatia", "Cyprus",
             "Czechia", "Estonia", "Gabon", "Hungary", "Iraq", "Jordan", "Kazakhstan", "Latvia", "Libya", "Lithuania", "Malaysia",
             "Maldives", "Mauritius", "Mexico", "North Macedonia", "Panama", "Poland", "Portugal", "Romania", "Serbia", "Slovakia",
             "Slovenia", "South Africa", "Trinidad and Tobago", "Uruguay")
group_4 <- c("Australia", "Austria", "Bahamas", "Bahrain", "Belgium", "Canada", "Denmark", "Equatorial Guinea", "Finland", "France",
             "Germany", "Greece", "Iceland", "Ireland", "Israel", "Italy", "Japan", "Kuwait", "Luxembourg", "Malta", "Netherlands",
             "New Zealand", "Norway", "Oman", "Qatar", "Saudi Arabia", "Singapore", "Spain", "Sweden", "Switzerland", "United Arab Emirates")


```

```{r}
library(ggplot2)

# Trasformazione del dataframe da formato wide a formato long
df_long <- tidyr::pivot_longer(combined_dataset, cols = starts_with("2"), names_to = "Year", values_to = "Value")
# Conversione del campo Year in formato numerico
df_long$Year <- as.numeric(gsub("X", "", df_long$Year))
df_long$Group=ifelse(df_long$GeoAreaName %in% group_1, "GROUP_1",
        ifelse(df_long$GeoAreaName %in% group_2, "GROUP_2",
               ifelse(df_long$GeoAreaName %in% group_3, "GROUP_3",
                      ifelse(df_long$GeoAreaName %in% group_4, "GROUP_4", ""))))

# Creazione del grafico con linee separate per ogni paese e colori basati sui gruppi
ggplot(df_long[1:504,], aes(x = Year, y = Value, color = Group, group = GeoAreaName)) +
  geom_path() +
  labs(x = "Anno", y = "Valore", color = "Gruppo") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1)) +
  scale_x_continuous(labels = function(x) as.integer(x))


```

#Tasso di Disoccupazione
```{r}
library(readxl)
tassodisoccupazione <- read_excel("C:/Users/39388/Downloads/tassodisoccupazione.xls")
tassodisoccupazione <- na.omit(tassodisoccupazione)
```
```{r}
tassodisoccupazione <- subset(tassodisoccupazione, `Country Name` %in% GDP$GeoAreaName)
tassodisoccupazione <- subset(tassodisoccupazione, select = -c(dim(tassodisoccupazione)[2]-1, dim(tassodisoccupazione)[2]))
GDP <- subset(GDP, GeoAreaName %in% tassodisoccupazione$`Country Name`)
```

```{r}
# Calcolo delle differenze percentuali tra le annate
diff_percent <- apply(tassodisoccupazione[, -1], 1, function(x) c(NA, diff(x) / x[-length(x)] * 100))
diff_percent_inverted <- t(diff_percent)

diff_percent_inverted <- cbind(tassodisoccupazione$`Country Name`, diff_percent_inverted)
colnames(diff_percent_inverted)[1] <- "CountyName"
diff_percent_inverted <- diff_percent_inverted[, -2]
diff_percent_inverted=as.data.frame(diff_percent_inverted)
```

```{r}

library(writexl)

# Specifica il percorso del file Excel di output
output_file <- "C:/Users/39388/Downloads/graftassdis.xlsx"

# Scrivi il dataset in un file Excel
write_xlsx(diff_percent_inverted, output_file)
```





